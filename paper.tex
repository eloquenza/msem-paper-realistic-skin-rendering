% This template has been tested with LLNCS DOCUMENT CLASS -- version 2.20 (10-Mar-2018)

% !TeX spellcheck = en-US
% !TeX encoding = utf8
% !TeX program = pdflatex
% !TeX TXS-program:compile = txs:///pdflatex/[--shell-escape]
% !BIB program = bibtex
% -*- coding:utf-8 mod:LaTeX -*-

% German documents: pass ngerman as class option
% \documentclass[ngerman,runningheads,a4paper]{llncs}[2018/03/10]
% English documents: pass english as class option
\documentclass[ngerman,runningheads,a4paper]{llncs}[2018/03/10]

\usepackage{improved-lncs}
\usepackage{subcaption}

\newcommand{\iu}{{i\mkern1mu}}

\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\begin{document}

\title{Subsurface scattering: Kombination von Theorie und Implementierungstechniken am Beispiel des realistischen Renderns von Haut}
%If Title is too long, use \titlerunning
\titlerunning{Realitische Echtzeitdarstellung von Haut}

%Single insitute
\author{Dennis Grabowski, B.Sc.}
%If there are too many authors, use \authorrunning
\authorrunning{D. Grabowski}

\institute{Hochschule Hannover, Ricklinger Stadtweg 120, 30459 Hannover, Germany\\
\email{dennis.grabowski@stud.hs-hannover.de}\\
\url{https://f4.hs-hannover.de/}}

\maketitle

\begin{abstract}

Unter dem typischen Phong-Modell ist es schwer, verschiedenste Materialien wie Marmor, Wachs, Blätter oder Haut realistisch dar\-zu\-stellen.
Zugrunde liegt, dass das Phong-Modell nur ein empirisches Model ist und keineswegs ein physikalisch exaktes Modell darstellt, wodurch verschiedenste physikalische Effekte schlichtweg nicht nachstellbar sind.
Diese Ausarbeitung wird ausleuchten, welche Schwierigkeiten sich dabei ergeben, Haut realistisch darzustellen und welche physikalischen Konzepte nötig sind, um diesen Realismus wiedergeben zu können.
Haut als Medium bietet sich besonders an, um an diese Konzepte heranzugehen, da jedem Leser ein realistische Erscheinungsbild dieser bekannt ist.
Hierfür wird zunächst aufgezeigt, wie Licht mit Haut interagiert, um die physikalischen Grundlagen der sogenannten Volumenstreuung (engl. subsurface scattering) kennenzulernen.
Anschliessend werden bestehende Techniken angeschnitten, die dieses physikalische Phänomen auf verschiedenste Weisen implementieren.
Durchleuchtet wird die sogenannte \enquote{Texture-space Diffusion}, welche bereits für den Film \enquote{The Matrix} verwendet wurde und von NVIDIA's d'Eon und Luebke für ein Echtzeit-Rendering-System adaptiert wurde.
Diese Technik verwendet die bidirektionale Reflexionsverteilungsfunktion von Kelemen und Szirmay-Kalos, um eine realistische Oberflächenreflexion zu simulieren, sowie Diffusionsprofile und Translucent Shadow Maps, um die Auswirkungen des Subsurface Scattering auf dem Hautmaterial nachzuahmen.

\end{abstract}

\begin{keywords}
  Computergrafik, Physikalisch-basiertes Rendering, Bidirektionale Reflexionsverteilungsfunktions (BRDFs), Subsurface scattering (deutsch Unterirdische Streuung/Volumenstreuung), Diffusionsprofile, Translucent shadow maps
\end{keywords}

\section{Einleitung}
\label{sec:intro}

Mithilfe des typischen Blinn-Phong-Modell ist es schwer, Materialien wie Marmor, Wachs, Blätter oder Haut realistisch darzustellen. Dies basiert auf dem Fakt, dass dies ein empirisches Modell ist, welches keineswegs versucht, in der Lage zu sein, alle physikalische Phänomene nachstellen zu können.
Um die zuvorgenannten Materialien realistisch darstellen zu können, sind komplexere, physikalisch-fundierte Konzepte wie beispielsweise das \enquote{Subsurface Scattering}, zu deutsch \enquote{Volumenstreuung}, erforderlich.
Dieses physikalische Phänomen beschreibt, wie Licht mit einem Objekt interagiert, nachdem es von diesem gebrochen, aber nicht reflektiert wird.

Das Ziel dieser Ausarbeitung ist es, das Prinzip der Volumenstreuung vorzustellen und dem Leser einen Überblick über mögliche Techniken zu verschaffen, um dieses Phänomen durch vorhandene Techniken der Computergrafik entweder physikalisch korrekt darzustellen oder zu approximieren.

Hierfür werden zunächst die physikalische Grundlagen aufgefrischt, die nötig sind um die Volumenstreuung zu verstehen, und erklärt warum der Aufbau des Objekts einen Unterschied für die Streuung darstellen kann.
Damit diese Erklärung relativ simpel bleiben kann, konzentriert sich diese Ausarbeitung auf Objekte, deren Oberfläche aus dem Material \enquote{Haut} bestehen.
Haut eignet sich besonders in diesem Kontext, da jedem Leser eine realistische Repräsentation dieses Materials wohl vertraut ist. Ferner sind Menschen darauf evolutionstechnisch trainiert, die feinsten Nuancen und Details instinktiv zu erkennen.

Nach Bewältigung der physikalischen Grundlagen werden 4 der bekanntesten realistischsten Haut-Render-Techniken vorgestellt, wovon der Fokus dieser Ausarbeitung auf der sogenannten \enquote{Texture-Space Diffusion} liegt, die bereits zum Film \enquote{The Matrix} Einsatz gefunden hat, und von NVIDIA's \citet{efficient-human-skin-rendering} angepasst wurde, um in einem Echtzeit-Renderer verwendet werden zu können.

Diese Technik kombiniert die Anwendung der \enquote{bidirektionalen Reflexions\-verteilungs\-funktion} von Kelemen und Szirmay-Kalos mit der Anwendung von sogenannten \enquote{Diffusionsprofilen} und \enquote{Translucent Shadow Maps}, um die realistische Darstellung von Haut zu ermöglichen.

Nachfolgend werden Bilder verschiedenster Implementationen sowie aktuellere Ergebnisse von \enquote{Offline-Renderern} miteinander vergliechen, um die Wirkung dieser Beleuchtungsmodelle besser einschätzen zu können.

\section{Physikalische Grundlagen der Volumenstreuung}

Um die Volumenstreuung vollständig verstehen zu können, bedarf es zunächst einer Auffrischung bezüglich der physikalischen Eigenschaften des Lichts und der generellen Lichtbrechung.

Licht ist eine Welle, die sich innerhalb eines Mediums (oder auch innerhalb eines Vakuums) geradlinig in eine Richtung fortbewegt.
In dieser Ausarbeitung bezeichnet Licht immer das für das menschliche Auge sichtbare Licht mit einer Wellenlänge von ungefähr 380 bis 800 nm. Andere elektromagnetische Strahlungen werden somit ignoriert.

Trifft eine Lichtwelle auf ein anderes Medium, so erfährt es den Effekt der \enquote{Streuung} - es teilt sich in verschiedene Richtungen auf. Dadurch ändert sich nicht die gesamte Intensität, jedoch teilt sich die Intensität auf mehrere Lichtstrahlen auf.
Dabei werden die Lichtstrahlen entweder von der Oberfläche reflektiert, von der Oberfläche gebrochen oder absorbiert.
Die genauen Effekte des Eintreffens auf die Oberfläche eines neuen Mediums hängen von mehreren Faktoren ab: dem Einfallswinkel des Lichts auf die Oberfläche des Objekts, der Beschaffenheit der Oberfläche und dem sogenannten \enquote{Brechungsindex}.

Da diese Ausarbeitung abzielt, die Volumenstreuung zu erklären, wird von einer näheren Erklärung der Auswirkungen von Einfallswinkeln sowie Oberflächenbeschaffungen abgesehen, da diese sich eher auf eine Reflexion auswirken.

Der Brechungsindex beschreibt das Verhältnis der Wellenlänge des Lichts im Vakuum zur Wellenlänge im Material und somit auch das Verhältnis der Phasengeschwindigkeit des Lichts im Vakuum zu der in dem betrachteten Material.
Es ist somit eine optische Eigenschaft eines Materials.
Besonders interessant ist die mathematische Darstellung dieses Index als komplexe Zahl: $$ \underline{n} = n + \iu * K$$
Der reelle Teil $n$ der komplexen Zahl beschreibt hierbei den Einfluss des Materials auf die Phasengeschwindigkeit des Lichts, wie stark das Licht durch das Material bei der Brechung verlangsamt wird, während der imaginäre Teil $\iu * K$ den Massenschwächungskoeffizienten beschreibt, ergo wie stark die Intensität des Lichts beim Propagieren durch das Material gedämpft wird.
Zusätzlich lässt sich mithilfe des Snelliussches Brechungsgesetzes und des Brechungsindex der Ausfallswinkel des gebrochenen Lichtstrahls in Relation zu dem Einfallswinkel des einfallenden Lichtstrahls berechnen.
Dadurch kann vorhergesagt werden, welchen Weg ein gebrochener Lichtstrahl innerhalb eines neuen Mediums nehmen wird - was eine hilfreiche Eigenschaft für das Rendern solcher gebrochenen Lichtstrahlen ist.

Was genau jedoch einem gebrochenen Lichtstrahl widerfährt, hängt von der Art des ihn brechenden Mediums ab.
Metalle absorbieren die gebrochenen Lichtstrahlen vollständig und wandeln diese in Hitze um.
Nicht-Metalle, sogenannte Dielektrika, wiederum verhalten sich wie reguläre Medien - innerhalb dieser interagieren gebrochenen Lichtstrahlen mit den Partikeln des Materials wie Lichtstrahlen, die auf die Oberfläche eines Mediums treffen - auch diese können absorbiert, wieder reflektiert, schlichtweg aus dem Objekt wieder emittiert werden oder sogar streuen.
Hierbei können die Dielektrika-Medien nach der Menge an unterschiedliche Brechungsindexen gruppiert werden, wodurch sich die Auswirkungen eines gebrochenen Lichtstrahls für eine Vielzahl von Materialien zusammenfassen lassen.
Transparente Medien, beispielsweise Glas oder Wasser, haben nur einen gleichbleibenden Brechungsindex, erlauben keine nennenswerte Absorption und lassen das Licht ohne Brechung durch sie passieren.
Homogene Medien, beispielsweise Bier, Kaffee, Wein oder Milch, haben zwar auch nur einen gleichbleibenden Brechungsindex, jedoch absorbieren sie eine signifikante Menge des Lichts. Dadurch ändert sich nicht die Richtung, allerdings die Intensität des Lichts wodurch sich der Farbunterschied dieser Medien erklären lässt.
Heterogene Medien, beispielsweise Holz, Stein, Plastik, wiederum haben basierend auf strukturellen Änderungen mehrere unterschiedliche Brechungsindexe. Diese strukturellen Änderungen basieren entweder auf der Unreinheit eines Materials - Luftblasen, mikroskopisch, kleine Fremdpartikel oder ähnliches - oder basieren auf der Unterteilung in verschiedene Schichten, die wiederum alle aus verschiedenen Materialen bestehen.
Ändern sich die Brechungsindexe eines heterogenen Mediums stetig, so wird das Licht gebogen.
Ändern sich diese jedoch abrupt, so streuen die Lichtstrahlen an jedem neuen Brechungsindex.
Hierbei ändert sich die Richtung sowie die Intensität der Lichtstrahlen, jedoch kann es auch zu einer Absorption der Lichtstrahlen kommen. \cite{hoffman2013background}

Problematisch wird jedoch die Betrachtung von gebrochenen Lichtstrahlen im Falle einer komplexeren Materialbeschaffenheit eines Objekts, beispielsweise Haut - dem Fokus dieser Ausarbeitung.
Verschiedene Hautschichten bestehen aus verschiedenen Materialien, wodurch sich verschiedene, abrupt-wechselende Unterschiede in den Brechungsindexen ergeben.
Jede neue Hautschicht absorbiert, reflektiert, bricht und streuut das Licht also auf ihre eigene Art und Weise.

Diese Streuung unterhalb der Oberfläche eines Objekts nennt sich \enquote{Subsurface scattering} oder zu deutsch \enquote{Volumenstreuung}.

\section{Subsurface scattering}
\label{sec:subsurface}

\begin{figure}
  \centering
  \includegraphics[scale=0.4,keepaspectratio]{./images/subsurface-scattering-illustration.jpg}
  \caption{Darstellung der Volumenstreuung in dielektrischen Materialien. Quelle: \cite{real-time-rendering}}
  \label{fig:subsurface-scattering}
\end{figure}

Die Volumenstreuung ist ein physikalisches Phänomen, welches beschreibt, was mit gebrochenen Lichtstrahlen innerhalb eines Objekts passiert.
Hierbei treffen an der Oberfläche des Objekts gebrochene Lichtstrahlen innerhalb des Objekts auf weitere, abrupte Änderungen, wodurch die gebrochenen Lichtstrahlen ferner in eine Vielzahl von Lichtstrahlen mit potentiell unterschiedlichen Intensitäten und potentiell allen möglichen Richtungen aufgeteilt werden.
Die Verteilung dieser Streuung hängt von dem Typen des Materials ab und ist häufig nicht uniform.

In Grafik \ref{fig:subsurface-scattering} wird dieser Effekt nochmal verdeutlicht. Der orangene Pfeil, der von oben rechts auf das neue Medium fällt, ist ein einzelner Lichtstrahl, der bei der Interaktion an der Oberfläche des Mediums streut. Ein Teil, erkenntlich durch die drei kleineren, orangenen Pfeile, die sich von dem Medium wieder entfernen, wird direkt von der Oberfläche reflektiert.
Die restlichen Lichtstrahlen werden mit der verbleibenden Intensität in verschiedenste Richtungen innerhalb des Mediums gebrochen und interagieren hierbei mit einzelnen Partikeln, die einen anderen Brechungsindex haben, als das Medium, in welchem sie sich befinden.
Verfolgt man die grünen Pfeile, so fällt auf, dass einige Lichtstrahlen vollständig von dem Medium absorbiert werden, wobei andere wieder von dem Objekt emittiert werden.
Hierbei müssen die wieder emittierten Lichtstrahlen nicht aus dem selben Punkt austreten, aus welchem sie ins Medium getreten sind. In der Grafik \ref{fig:subsurface-scattering-different-exit-point} wird nochmal verdeutlicht, wie stark der Austrittspunkt mancher der dargestellten Lichtstrahlen von dem Eintrittspunkt des ersten, einfallenden Lichtstrahls abweichen.

\begin{figure}
  \centering
  \includegraphics[scale=0.3,keepaspectratio]{./images/subsurface-scattering-distance-difference.jpg}
  \caption{Distanzunterschiede sind zwischen den Austrittspunkten und dem Eintrittspunkt zu erkennen. Quelle: \cite{real-time-rendering}}
  \label{fig:subsurface-scattering-different-exit-point}
\end{figure}

Aus den Grafiken \ref{fig:subsurface-scattering} und \ref{fig:subsurface-scattering-different-exit-point} ist ebenfalls erkenntlich, dass Lichtstrahlen unterschiedlich oft innerhalb eines Mediums streuen, bevor sie wieder von diesem Medium emittiert werden.
Man unterscheidet hierbei zwischen dem \enquote{Single-bounce scattering} und dem \enquote{Multiple-bounce scattering}; frei übersetzt der einfachen Streuung und der mehrfachen Streuung.

\subsection{Konzeptionelle Adaptation der Volumenstreuung in der Computergrafik}

Appliziert man die eben gewonnenen Erkenntnisse auf die Computergrafik, so kann man die Distanzunterschiede der neu-emittierten Lichtstrahlen in Abhängigkeit von Pixelgrössen darstellen, wie in Grafik \ref{fig:subsurface-scattering-pixel-considerations} dargestellt ist.

\begin{figure}
  \centering
  \includegraphics[scale=0.2,keepaspectratio]{./images/subsurface-scattering-pixel-considerations.jpg}
  \caption{Distanzunterschiede der neu-emittierten Lichtstrahlen in Abhängigkeit verschiedener Pixelgrössen. Quelle: \cite{real-time-rendering}}
  \label{fig:subsurface-scattering-pixel-considerations}
\end{figure}

Innerhalb dieser Grafik ist das bereits vorgestellte Beispiel zur Volumenstreuung um einen grünen Kreis erweitert wurden, der die Grösse eines Pixels signalisieren soll.
Die linke Darstellung in der ersten Reihe zeigt somit ein Szenario, bei welchem die Distanz der Austrittspunkte der neu-emittierten Lichtstrahlen in Relation zu dem Eintrittspunkt des einfallenden Lichtstrahls kleiner ist als ein Pixel.
Dieses Szenario wird in der rechten Darstellung der ersten Reihe  vereinfacht dargestellt, in dem ein Renderer die Austrittspunkte in der Mitte des Pixels simuliert.
Die untere Abbildung zeigt den anderen Fall: Die Austrittspunkte sind ausserhalb des Pixels des einfallenden Lichtstrahls.

Diese Szenarien werden als lokale und globale Volumenstreuung kategorisiert.
Bei einer lokalen Volumenstreuung kann die Beleuchtung jedes Pixels individuell berechnet werden.
Dadurch ermöglichen sich beispielsweise Performancegewinne durch Parallelität oder den Wechsel zu dieser Methode beim Rendern von weit entfernten Charakteren.
Implementiert werden lokale Volumenstreuungen normalerweise durch eine \enquote{Lambert'sche  bidirektionale Reflektionsverteilungsfunktion}, die in der Lage ist, diffuse Reflektion mathematisch darzustellen. Die Lambert'sche BRDF hat normalerweise folgende mathematische Definition: $f_{Lambert}(l, v) = \rho_{ss} / pi$ \cite{real-time-rendering}
Hierbei beschreiben $l$ den Einheitsvektor des einfallenden Lichtstrahles, $v$ den ausgehenden Einheitsvektor der Blickrichtung und $\rho_{ss}$ die \enquote{Untergrundalbedo}.
Die Albedo eines Dielektrika ist definiert als das Verhältnis von der Radiosität, die von dem bestrahlten Objekt ausgeht, zu der Bestrahlungsstärke, die auf die Oberfläche einfallt.
Sie kann einen Wert zwischen 0 (jegliche Lichtstrahlen werden absorbiert) und 1 (keine Lichtstrahlen werden absorbiert) belegen, und hängt ferner von der Wellenlänge des jeweiligen Lichtstrahls ab, weshalb sie oftmals als RGB-Vektor modelliert wird.\cite{real-time-rendering}

Die eben vorgestellte mathematische Definition beruecksichtigt allerdings nicht, dass die Lichtstrahlen, welche von der Oberflaeche reflektiert werden, nicht fuer die Volumenstreuung nutzbar sind.
Eine typische Verbesserung waere daher, den Fresnelschen Effekt zu beachten, welcher impliziert, dass bei einer Oberflächenreflexion sich die Menge an direkten Lichtstrahlen erhoehert und die Menge an diffusen Lichtstrahlen abnimmt, wenn zunehmend schraegere Einfallswinkel betrachtet werden.
Mathematisch laesst sich dies wie folgt ausdruecken:
$f_{diff}(l, v) = (1 - F(n, l)) * \rho_{ss} / pi$ \cite{real-time-rendering}
Hier beschreibt $n$ die typische Oberflaechennormale.

Typischerweise ignorieren diese BRDFs die Einflüsse anderer Pixel, wodurch sie sich nicht bei einer Darstellung mit globalen Volumenstreuung eignen.
Bei einer globalen Volumenstreuung kann die Beleuchtung jedes Pixels potentiell die Beleuchtung jedes anderen Pixels des Bildes beeinflussen.
Diese Streuungen werden üblicherweise durch \enquote{globale Beleuchtungsmodelle} wie beispielsweise \enquote{Raytracern} dargestellt.
Auch einer der Vorreiter der realistischsten Haut-Render-Techniken, der BSSRDF von \citet{spectral-bssrdf-human-skin}, bedient sich dieser Methodik.
Für eine realistische Repräsentation ist ein Beleuchtungsmodell, welches globale Volumenstreuung berücksichtigt, unumgänglich.
Jedoch haben diese gewaltige Performanceimplikationen, wodurch Annäherungen oder ähnliche \enquote{Tricks} angewendet werden müssen.

\subsection{Struktur der Hautschichten}

Bevor die Vorstellung verschiedener Techniken zum realistischen Rendering des Materials Haut sinnvoll erscheint, sollte zunächst untersucht werden, wie die menschliche Haut strukturiert ist und welche physikalischen Eigenschaften sie besitzt.

\begin{figure}
  \centering
  \includegraphics[scale=0.275,keepaspectratio]{./images/skin-layers-medical.png}
  \caption{Anatomisch korrekte Unterteilung der Haut in ihre Schichten. Quelle: \cite{anatomic-skin-model}}
  \label{fig:real-skin-layers}
\end{figure}

Die Grafik \ref{fig:real-skin-layers} zeigt eine medizinisch korrekte Darstellung der Zusammensetzung der unterschiedlichen Hautschichten. Die Haut ist somit ein heterogenes Medium.

Konzeptionell ist die Haut aufgeteilt in 3 Schichten: die Epidermis, die Dermis und die Hypodermis.
Direkt erkenntlich ist, dass sich die unterschiedlichen Schichten, keineswegs das Volumen der Haut uniform aufteilen.
Die Hypodermis und die Dermis machen einen höheren Anteil der Haut aus, während die Epidermis hingegen die aüsserste Schicht bildet, und somit als erstes mit einfallenden Lichtstrahlen interagiert.
In der Grafik leider nicht dargestellt ist das Sebum, eine ölige Substanz, die sich über Hautoberfläche zieht und für ihren Glanz sorgt.
Ferner bestehen alle Schichten aus unterschiedlichen Materialien und sind von unterschiedlichen \enquote{Fremdpartikeln} durchzogen.
Haare oder Schweisporen strecken sich von der Hypodermis bis hin zur Epidermis.
Feine Venen und Arterien ziehen sich durch alle Schichten, um die Blutgefässe der Haut mit ausreichend Blut versorgen zu können.
All diese Materialien verursachen, dass gebrochene Lichtstrahlen in die unterschiedlichsten Richtungen mit den unterschiedlichsten Intensitäten gestreuut werden.
Eine exakte Repräsentation dieses Modells erweist sich daher als unhandlich für das realistische Rendering der Haut.

Laut \citet{tuchin2015tissue} werden \textasciitilde{}6\% des einfallenden Lichts direkt an der Hautoberfläche dank des Sebums reflekiert, während die restlichen \textasciitilde{}94\% Lichtstrahlen innerhalb der Haut der Volumenstreuung unterliegen.
Für die reflektierten Lichtstrahlen ist hauptsächlich das Sebum verantwortlich.
Die Stratum Corneum ist hingegen höchst streuend, wodurch viele, multiple Streuungen stattfinden.
Ferner haben alle Bestandteile unterhalb der Dermis keinen nennenswerten Effekt auf die fürs menschliche Auge wahrgenommene Erscheinung \cite{tuchin2015tissue}.

Erforderlich ist somit ein Beleuchtungsmodell, dass den geringen Anteil der direkt reflektierten Lichtstrahlen und deren richtige Verteilung korrekterweise wiedergeben kann, sowie in der Lage ist eine globale Volumenstreuung zu simulieren.
Simulieren bedeutet hier, dass nicht unbedingt eine wissenschaftlich umfassende Präsentation erforderlich ist.
Möglich ist auch eine Approximation.

\section{Texture-Space Diffusion}
\label{sec:texture-space}

Die sogenannte \enquote{Texture-Space Diffusion} ist eine von NVIDIA's \citet{efficient-human-skin-rendering} fortgefuehrte Methodik, die sich auf den Ergebnissen von \citet{realistic-human-face-rendering-matrix} stützt.
Diese versuchten für die Trilogie \enquote{The Matrix} eine Rendertechnik zu finden, mithilfe welcher sie in der Lage sind, Haut auch realistisch  im Falle des \enquote{Morphing} des \enquote{Agent Smith} darstellen zu können.
Während ihrer Forschung ist ihnen aufgefallen, dass ein realistisches Ergebnis ohne Volumenstreuung nicht möglich ist.
Die bis dato veröffentlichten Techniken waren jedoch entweder rechnerisch zu kostspielig oder lieferten eher enttäuschende Ergebnisse.
Daher entwickelteten \citet{realistic-human-face-rendering-matrix} die Beleuchtungstechnik, \enquote{Texture-Space Diffusion}, die die Effekte der Volumenstreuung in Falle der menschlichen Haut approximiert.

Im Rahmen des vorgestellten wissenschaftlichen Artikels \enquote{Efficient Rendering of Human Skin} von \citet{advanced-realtime-skin-rendering} wird diese Technik innerhalb eines vollständiges Beleuchtungsmodelles verwendet, welches speziell zum Echtzeit-Rendern realistischer, menschliche Haut erstellt wurde.

Das vollständige Beleuchtungsmodell besteht daher aus:

\begin{itemize}
  \item Der BRDF von Kelemen und Szirmay-Kalos, um Lichtstrahlen zu modellieren, die direkt von der Hautoberfläche reflektiert werden,
  \item Diffusionsprofilen, die innerhalb der Texture-Space-Diffusion verwendet werden,
  \item und modifizierte \enquote{Translucent Shadow Maps} \citep{translucent-shadow-maps}, durch welche die korrekte Durch-/Beleuchtung duennere Hautpartien ermoeglicht wird
\end{itemize}

Die vorgestellte Technik bezieht ihren Namen aus dem Fakt, dass die gesamte Simulation der Volumenstreuung in einer 2D-Texture des Objektmeshes unter Verwendung der UV-Parametrisierung erfolgt.

\subsection{Verwendetes Hautmodell}
\label{sub:skin-model}

\begin{figure}
  \centering
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[scale=0.5,keepaspectratio]{./images/multilayer-skin-specular-reflection.jpg}
    \label{fig:multilayer-specular}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[scale=0.5,keepaspectratio]{./images/multilayer-skin-subsurface.jpg}
    \label{fig:multilayer-subsurface}
  \end{subfigure}
  \caption{Links: Oberflächenreflexion im 3-Schicht-Hautmodell, Rechts: Volumenstreuung im 3-Schicht-Hautmodell.\\\hspace{\textwidth}Quelle: \citet{efficient-human-skin-rendering}}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=0.25,keepaspectratio]{./images/importance-of-layer-amount}
    \caption{Links: 3-Schicht-Hautmodell, rechts: 1-Schicht-Hautmodell.\\\hspace{\textwidth}Quelle: \citet{efficient-human-skin-rendering}}
\end{figure}

Die Haut im rechten Bild sieht wachsartig aus.

\subsection{Von der Hautoberfläche reflektierte Lichtstrahlen}
\label{sub:skin-surface-reflect}

Die Autoren \citeauthor{efficient-human-skin-rendering} verwenden fuer Lichtstrahlen, die direkt von der Hautoberfläche reflektiert werden, die BRDF von Kelemen und Szirmay-Kalos \cite{kelemen2001microfacet}.
Sie weichen von der Wahl der \enquote{Cook-Torrance}-BRDF, die in \citet{spectral-bssrdf-human-skin} verwendet wurde, ab und begründen diese alternative BRDF damit, dass die \enquote{Kelemen und Szirmay-Kalos}-BRDF signifikant weniger rechenintensiv sei, waehrend sie ein aehnliches, visuelles Ergebnis liefert (Begründung ebenfalls in \cite{hoffman2013background} zu finden).
Diese BRDF ist allgemein mathematisch wie folgt definiert\footnote{Formel entnommen von \cite[p.~352]{real-time-rendering}, die ihrerseits \cite{kelemen2001microfacet} als Quelle angibt}: $$f_{diff}(l, v) = \rho_{ss} * \frac{(1 - R_{spec}(l))* (1 - R_{spec}(v))}{\pi * (1 - \overline{R_{spec}})}$$

Hier beschreibt $R_{spec}$ die direkt von der Oberfläche reflektierten Lichtstrahlen der BDRF (in der Literatur auch manchmal aus \enquote{direktionale Albedo} bezeichnet) und $\overline{R_{spec}}$ das Kosinus-gewichtete Integral der direktionalen Albedo ueber die Einheitshemisphaere, die sich mithilfe des Normalenvektors auf der Oberfläche bilden laesst.
Dies laesst sich dadurch erklären, dass potentiell jeder moegliche Einfallswinkel etwas Strahlungsstaerke mit sich traegt.

Ferner wird innerhalb des Verfahrens die BRDF durch folgende Anpassungen berechnungseffizienter gestaltet.
$rho_{ss}$ (sowie $m$) nehmen vorbestimmte Werte, die einer Studie von \citet{weyrich2006analysis} entnommen werden koennen, an, um Berechnungsaufwand zu sparen.
Die Autoren geben darueber hinaus an, dass sie $\rho_{dt}$, eine \enquote{diffuse transmission function} vorberechnen, indem fuer verschiedene \enquote{Roughness}-Werte $m$ eine vorberechnete Beckmann-Verteilungs-Funktion angewandt wird und die Ergebnisse innerhalb einer 2D-Texture gespeichert werden.
Leider spezifizieren die Autoren nicht, wofuer diese Funktion genau verwendet wird, ebenso konnten keine Informationen zu dieser \enquote{diffuse transmission function} und ihren Einsatz gefunden werden.
\\
\\
In Grafik \ref{fig:outlook-final-result-no-sss} (a) kann die gerenderte Haut betrachtet werden, wenn nur die BRDF von Kelemen und Szirmay-Kalos appliziert wird.

\subsection{Unter der Hautoberfläche streuende Lichtstrahlen}
\label{sub:skin-subsurface-reflect}

\subsubsection{Diffusionsprofile}
\label{sub:diffusion-profiles}

\begin{itemize}
  \item Approximation für die Lichtstreuverteilung unter der Oberfläche eines stark streuenden Materials
  \item Einfaches Experiment: Beleuchten einer flachen Oberfläche in einem dunklen Raum mit einem dünnen, weißen Laserstrahl.
  \item berechnen das Diffusionsprofil als Summe der Gaußschen
\end{itemize}

Diese Approximation basiert auf Forschungsergebnissen von \citet{stam1995multiple} und \citet{spectral-bssrdf-human-skin}, die später von \citet{ma2007rapid} erweitert wurde.
\citeauthor{stam1995multiple}'s Forschung ergab, dass multiple Volumenstreuungen als Diffusionsprozess modelliert werden können.
Das Beleuchtungsmodell, das aus der Forschung von \citeauthor{spectral-bssrdf-human-skin} entstanden ist, hat diese Idee aufgegriffen, um eine analytische BSSRDF speziell für das Rendern von Haut abzuleiten; eine BRDF für den Fall einer globalen Volumenstreuung generalisiert.

based on an technique called Normal blurring
an idea by Ma et al based on measured data that showed reflected lights from scattered objects specular reflecntance is based on geometric surface normals, diffuse reflectance behave as if it uses blurred surface normals
a technique popularized by \citet{realistic-human-face-rendering-matrix} for the film Matrix formalizes the idea of multiple scattering as a blurring process of a texture
Object mesh unwrapped onto a 2D texture
surface irradiance aka diffuse lighting is rendered into a texture
done by using texture coordinates as positions for rasterization.
this texture is then blurred and used for diffuse shading when rendering
shape/size of filter for blurring depends on material and wavelength
  for skin, a wider filter is used on R channel than on G or B channel causing the reddening near shadow edges
  most often, correct filter has narrow spike in the center, wide shallow base
  Reapplies blurred texture back onto the 3D model
  Subsurface scattering is therefore simulated by blurring
this technique is very expensive, requiring large number of blurring passes - scaling back is possible for performance, but comes at a cost of realism


light distribution tends to be isotropic in a highly scattering media - i.e. once light is in the surface, it's randomly likely to end up coming out any direction rather being mostly aligned to the incoming light direction or any other similar possible dependency term
this makes scattering sort of a blurring function
comes from stam, 1995 - multiple scattering as a diffusion profile
        based on two parts:
          one method for exact computation of single-scattering contribution
          dipole method that approximates the multiple-scattering contribution by evaluating two virtual point light sources, one below and one above the surface


\begin{figure}
\includegraphics[scale=1,keepaspectratio]{./images/diffusion-profile-visualization}
\caption{TODO}
\end{figure}

\begin{itemize}
  \item Wir sehen ein glühendes Zentrum, das auf die Tatsache zurückzuführen ist, dass einige Lichtstrahlen durch die Oberfläche gestreut werden und in der Nähe zurückkehren.
  \item Dies sagt uns effektiv, wie viel Licht als Funktion des Winkels und der Entfernung vom Laserzentrum austritt.
  \item In uniformen Materialien ist die Streuung gleich, der Winkel ist hierbei irrelevant
  \item Jede Farbe hat ihr eigenes Diffusionsprofil, wie manche von der rechten Seite herleiten könnten.
  \item Donner und Jenson verwenden 150 verschiedene Diffusionsprofile für ihre spektrale BSSRDF
\end{itemize}

Diffusionprofile implementiert via einer Summe aus Gaussians

\begin{itemize}
  \item Definition der Gaußschen Verteilung: $G(v, r) = \frac{1}{2 * \pi * v} * e^{\frac{-r^{2}}{2*v}}$
  \item $R(r) = \sum\nolimits_{i=1}^k w_i * G(v_i, r)$
\end{itemize}

\begin{figure}
\includegraphics[scale=0.8,keepaspectratio]{./images/approximation-gaussians}
\caption{TODO}
\end{figure}

\begin{itemize}
  \item Die Autoren sahen in den aufgezeichneten Kurven eine Ähnlichkeit mit der bekannten Gaußschen Funktion $e^{-r^2}$
  \item Anstatt ein Diffusionsprofil für die Haut zu messen, nähern sich die Jungs von NVIDIA dem Diffusionsprofil an, das Donner \& Jensen in ihrer Forschung gefunden hat
  \item Summen von Gaussians schienen eine ausgezeichnete Annäherung zu bieten
  \item Gaussians wurden verwendet, weil sie gleichzeitig trennbar und radial symmetrisch sind
  \item $R(r)$ = ein Diffusionsprofil
  \item Konstanter Faktor in der Gaußschen Varianz wurde so gewählt, dass radiale 2D-Unschärfe das Eingangsbild nicht verdunkelt oder aufhellt
  \item $r$ steht für Radius
  \item Auffinden von $k$-Gaussien mit unterschiedlichen Gewichten und Varianzen
  \item Die Autoren verwenden tatsächlich eine Sechs-Gauss-Zusammenfassung, um das in Donner/Jensen 2005 gegebene Drei-Schichten-Modell genau abzubilden
\end{itemize}

\subsection{Anwendung der Diffusionsprofile zur Simulation der Volumenstreuung}

\begin{figure}
  \centering
  \includegraphics[scale=0.8,keepaspectratio]{./images/texture-space-algorithm.jpg}
  \caption{Source: \citet{efficient-human-skin-rendering}}
\end{figure}

\begin{itemize}
  \item Rasterize irradiance onto texture via vertex shader (U,V are texture coordinates)
  \item Compute lightning and fresnel terms in fragment shader (excluding specular)
  \item Ultimately more efficient as operations like convolutions can be performed more efficiently in image space
\end{itemize}

\begin{enumerate}
  \item Render shadow maps
  \item Render stretch correction map (optional: it may be precomputed).
  \item Render irradiance into off-screen texture.
  \item For each Gaussian kernel used in the diffusion profile approximation:
    \begin{itemize}
      \item Perform a separable blur pass in U (temporary buffer)
      \item Perform a separable blur pass in V (keep all of these for final pass).
    \end{itemize}
  \item Render mesh in 3D:
    \begin{itemize}
      \item Access each Gaussian convolution texture and combine linearly.
      \item Add specular for each light source.
    \end{itemize}
\end{enumerate}

\begin{figure}
  \centering
  \includegraphics[scale=0.9,keepaspectratio]{./images/irradiance-texture-adrian.jpg}
  \caption{Source: \citet{efficient-human-skin-rendering}}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=0.9,keepaspectratio]{./images/skin-rendering-with-without-sss.jpg}
  \caption{Ergebnis der \enquote{Texture-Space-Diffusion}-Technik, links ohne Volumenstreuung, rechts mit.\\\hspace{\textwidth}Quelle: \citet{efficient-human-skin-rendering}}
  \label{fig:outlook-final-result-no-sss}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=0.4,keepaspectratio]{./images/human-skin-final-rendering.jpg}
  \caption{Source: \citet{efficient-human-skin-rendering}}
\end{figure}

\begin{enumerate}
  \item First albedo,
  \item irradiance,
  \item Combine both to calculate subsurface irradiance,
  \item Do all gaussian blurs in texture space
  \item combine with specular
  \item produce final image!
  \item All convulutions are performed in 2d texture space but here mapped onto the face
\end{enumerate}

\subsection{Translucent Shadow Maps}
\label{sub:translucent-shadow-maps}

Schwierig sind vor allem dünnere Hautpartien, durch welche (gebrochene, gestreute) Lichtstrahlen durchscheinen können.
Während \citet{realistic-human-face-rendering-matrix} hier für realistische Ergebnisse auf einen Raytracer zurückgreifen, hielten \citet{efficient-human-skin-rendering} diesen Ansatz für einen Echtzeitrenderer für zu rechenintensiv.
Um dennoch dünne Hautpartien realistisch darstellen zu können, verwenden \citet{realistic-human-face-rendering-matrix} sogenannte \enquote{Translucent Shadow Maps}.

\begin{figure}
  \includegraphics[scale=0.2,keepaspectratio]{./images/translucent-shadow-maps.jpg}
  \caption{
    Dünne Hautpartien gerendert durch verschiedene Techniken.\\\hspace{\textwidth}
    Links: Texture-Space Diffusion, Mitte: Rendering mit Translucent Shadow Maps, Rechts: spektrales BSSRDF-Modell von Jensen et al.\\\hspace{\textwidth}Quelle: \citet{efficient-human-skin-rendering}
  }
\end{figure}

\citet{translucent-shadow-maps}

\begin{itemize}
  \item Transluzente Schattenkarten verwenden
  \item An Ohren, Nasenlöchern und anderen dünnen Hautregionen liegen die beiden Oberflächenorte im 3D-Raum sehr nahe beieinander, aber nicht im Texturraum, der die Streuung unter der Oberfläche nicht korrekt berechnet
  \item \citet{efficient-human-skin-rendering} modifizierte die translucent shadow maps, um eine sehr effiziente Abschätzung der Diffusion durch dünne Regionen durch die Wiederverwendung von gefalteten Bestrahlungstexturen zu ermöglichen.
\end{itemize}

\section{Konklusion und Ausblick}
\label{sec:outlook}

Das zusammengestellte, fertige Ergebnis der \enquote{Texture-Space Diffusion} Technik kann in Grafik \ref{fig:outlook-final-result} betrachtet werden.
In Grafik \ref{fig:outlook-final-result-no-sss} ist sicherbar, welchen Unterschied die simulierte Volumenstreuung im Kontext der verwendeten Technik macht.
Zweifelsohne laesst sich sagen, dass das Ergebnis sich sehen laesst.
Verglichen mit dem Ergebnis, dass sich durch die damalige \enquote{state-of-the-art} BSSRDF von Donner und Jensen \cite{spectral-bssrdf-human-skin}, rendern laesst, kann behauptet werden, dass sie ein sehr aehnliches Ergebnis erzielten.
\\

Jedoch ist die \enquote{Texture-Space-Diffusion} nicht ohne Limitationen oder Fehler.
Die Translucent Shadow Maps leiden laut \citet{efficient-human-skin-rendering} unter den Problematiken der reguläre Shadow Maps, beispielsweise der Auswahl der angemessenen Aufloesungen.
Darueber hinaus ist man zu der Benutzung einer kleinen Menge an vorbestimmten Punktlichtquellen limitiert, da die Benutzung der Translucent Shadow Maps den Nachteil birgt, dass neue neue Lichtquelle das Speichern einer weiteren Shadow Map mit sich bringt.
Auch die Performance in Umgebungen mit mehreren menschlichen Charakteren laesst zu wuenschen ueber.
Jedes Objektmesh durchlaeuft diesen Prozess und es ist nicht in Texture-Space erkenntlich, wie gross der jeweilige Charakter letztendlich auf dem Bildschirm sein wird, wodurch sich oftmals unnoetigerweise Berechnungen ergeben, wenn der Charakter potentiell nur einige Pixel auf dem finalen Bild einnimmt.
Direkt daraus ist die Forschung bezueglich der \enquote{Screen-Space}-Variante dieser Technik von \citet{screen-space-subsurface} entstanden.
Wie in Grafik \ref{fig:outlook-ssss} gezeigt wird, laesst sich auch dieses Ergebnis sehen.

\begin{figure}
  \centering
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[scale=0.2,keepaspectratio]{./images/bssrdf-head.jpg}
    \caption{Ergebnis der BSSRDF von \citet{spectral-bssrdf-human-skin}}
    \label{fig:outlook-bssrdf}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[scale=0.25,keepaspectratio]{./images/nvidia-result.jpg}
    \caption{Ergebnis der Texture-Space-Diffusion innerhalb eines Echtzeit-Renderers mit 2 Punkt-Lichtquellen, einer Umgebungslichtquelle und 2 teilbaren Bloomfiltern.
    \\\hspace{\textwidth}Quelle: \cite{efficient-human-skin-rendering}}
    \label{fig:outlook-final-result}
  \end{subfigure}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=0.275,keepaspectratio]{./images/screen-space-sss.jpg}
  \caption{Ergebnis der Screen-Space-Variante des betrachteten Algorithmus.\\\hspace{\textwidth}Quelle: \citet{screen-space-subsurface}}
  \label{fig:outlook-ssss}
\end{figure}

Zu hoffen bleibt jedoch, dass die Ergebnisse heutiger \enquote{Offline-Renderer} wie sie in den Grafiken \ref{fig:outlook-volumetric-path-tracer} und \ref{fig:outlook-monte-carlo-ray-tracer} zu sehen sind, in zukünftigen Echtzeitrenderer moeglich werden.
Entweder durch Durchbrüche in der Forschung oder durch effizientere Consumer-Level-Hardware.
Die neue Grafikkarten-Reihe \enquote{Geforce RTX} von NVIDIA verwendet beispielsweise \enquote{Tensorprozessoren}, um eine Beschleunigung der \enquote{Ray Tracing}-Berechnungen zu erzielen \cite{forbes-tensor-rtx}.
Moeglicherweise wird dadurch Ray Tracing zukünftig eine gewoehnliche Technik fuer PCs.

\begin{figure}
\includegraphics[scale=0.275,keepaspectratio]{./images/framestore-digital-gamora.jpg}
\caption{\enquote{Gamora} aus \enquote{Guardians of the Galaxy}, gerendert durch einen volumetrischen Path Tracer, der von Framestore, eines High-End VFX-Studios, entwickelt wurde. Sehr rechenintensiv, daher nicht für interaktives zurzeit verwendbar - Quelle: \cite{volumetric-path-tracer}}
\label{fig:outlook-volumetric-path-tracer}
\end{figure}

\begin{figure}
\includegraphics[scale=0.275,keepaspectratio]{./images/monte-carlo-ray-tracer.jpg}
\caption{Die Ergebnisse eines \enquote{Monte Carlo}-Raytracers implementiert in der Forschungsarbeit von \citet{weyrich2006analysis}.\\\hspace{\textwidth}In der oberen Reihe befinden sich die aufgenommenen Bilder, in der unteren Reihe die gerendereten Ergebnisse.}
\label{fig:outlook-monte-carlo-ray-tracer}
\end{figure}

\newpage

\nocite{advanced-realtime-skin-rendering}

\renewcommand{\bibsection}{\section{Referenzen}} % requried for natbib to have "References" printed and as section, not chapter
% Use natbib compatbile splncsnat style.
% It does provide all features of splncs03, but is developed in a clean way.
% Source: http://phaseportrait.blogspot.de/2011/02/natbib-compatible-bibtex-style-bst-file.html
\bibliographystyle{splncsnat}
\begingroup
  \ifluatex
    %try to activate if bibliography looks ugly
    %\sloppy
  \else
    \microtypecontext{expansion=sloppy}
  \fi
  \small % ensure correct font size for the bibliography
  \bibliography{paper}
\endgroup

% Enforce empty line after bibliography
\ \\
%
Alle URLs wurden zuletzt am 21.05.2020 besucht.
\end{document}
